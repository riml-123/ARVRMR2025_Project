{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f14525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\torch\\onnx\\_internal\\registration.py:167: OnnxExporterWarning: Symbolic function 'aten::scaled_dot_product_attention' already registered for opset 14. Replacing the existing function with new function. This is unexpected. Please report it on https://github.com/pytorch/pytorch/issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'subfolder': '', 'trust_remote_code': False} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:236: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_length > max_position_embedding:\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:94: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1 or self.sliding_window is not None:\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\optimum\\exporters\\onnx\\model_patcher.py:259: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_weights = original_scaled_dot_product_attention(\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:5859: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1110: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if dim % default_overall_up_factor != 0:\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\downsampling.py:136: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\downsampling.py:145: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\upsampling.py:147: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\upsampling.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.shape[0] >= 64:\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\upsampling.py:173: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.numel() * scale_factor > pow(2, 31):\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1308: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\torch\\onnx\\utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "c:\\Users\\Taeyong_Sim\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\torch\\onnx\\utils.py:1209: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "You have disabled the safety checker for <class 'optimum.onnxruntime.modeling_diffusion.ORTStableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "from optimum.onnxruntime import ORTStableDiffusionImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(ort.get_device())\n",
    "\n",
    "model_id =\"stabilityai/sd-turbo\"\n",
    "pipeline = ORTStableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=\"fp16\",            # FP16은 GPU provider에서만\n",
    "    use_io_binding=True,\n",
    "    export=True,\n",
    "    provider=\"CUDAExecutionProvider\"  # 꼭 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583c4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "from typing import Optional\n",
    "from flask import Flask, request, send_file, jsonify\n",
    "from flask_cors import CORS\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572d5d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taeyong_Sim\\Desktop\\School\\3-2\\AR, MR, VR\\GitHub\\ARVRMR2025_Project\\Server\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "# style transfer ONNX 경로 (이미 있다고 가정한 변수)\n",
    "%cd ./\n",
    "style_transfer_model_path = \"./models/AdaIN.onnx\"\n",
    "\n",
    "# AdaIN ONNX 세션 생성\n",
    "adain_session = ort.InferenceSession(\n",
    "    style_transfer_model_path,\n",
    "    providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "# 서버에 있는 스타일 이미지 리스트 (원하는 걸로 바꿔 넣기)\n",
    "STYLE_IMAGE_DIR = \"./styles\"\n",
    "STYLE_IMAGE_FILES = [\n",
    "    os.path.join(STYLE_IMAGE_DIR, \"style1.jpg\"),\n",
    "    os.path.join(STYLE_IMAGE_DIR, \"style2.jpg\"),\n",
    "    os.path.join(STYLE_IMAGE_DIR, \"style3.jpg\"),\n",
    "    os.path.join(STYLE_IMAGE_DIR, \"style4.jpg\"),\n",
    "]\n",
    "\n",
    "STYLE_IMAGES = [Image.open(p).convert(\"RGB\") for p in STYLE_IMAGE_FILES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4082687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_nchw(img: Image.Image, size: int = 512) -> np.ndarray:\n",
    "    img = img.resize((size, size))\n",
    "    arr = np.array(img).astype(\"float32\") / 255.0   # HWC, 0~1\n",
    "    arr = np.transpose(arr, (2, 0, 1))             # CHW\n",
    "    arr = np.expand_dims(arr, 0)                   # 1CHW\n",
    "    return arr\n",
    "\n",
    "def nchw_to_img(arr: np.ndarray) -> Image.Image:\n",
    "    # arr: (1,3,H,W) or (3,H,W)\n",
    "    if arr.ndim == 4:\n",
    "        arr = arr[0]\n",
    "    arr = np.clip(np.transpose(arr, (1, 2, 0)), 0.0, 1.0)  # HWC\n",
    "    arr_uint8 = (arr * 255).astype(\"uint8\")\n",
    "    return Image.fromarray(arr_uint8)\n",
    "\n",
    "def run_adain(content_img: Image.Image, style_img: Image.Image) -> Image.Image:\n",
    "    c = img_to_nchw(content_img, size=512)\n",
    "    s = img_to_nchw(style_img, size=512)\n",
    "    out = adain_session.run(None, {\"content\": c, \"style\": s})[0]  # (1,3,512,512)\n",
    "    return nchw_to_img(out)\n",
    "\n",
    "def pil_to_base64(img: Image.Image) -> str:\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, format=\"PNG\")\n",
    "    buf.seek(0)\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69ffcca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 2) Flask 앱\n",
    "# -----------------------\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # WebGL/브라우저에서 접근할 경우를 대비\n",
    "\n",
    "def to_rgb_image(file_storage) -> Image.Image:\n",
    "    data = file_storage.read()\n",
    "    img = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "@app.route(\"/health\", methods=[\"GET\"])\n",
    "def health():\n",
    "    return jsonify({\"status\": \"ok\", \"provider\": \"CUDAExecutionProvider\"})\n",
    "\n",
    "@app.route(\"/infer\", methods=[\"POST\"])\n",
    "def infer_combo():\n",
    "    \"\"\"\n",
    "    요청:\n",
    "      - form-data:\n",
    "        - image: PNG 파일 (Unity에서 보낸 원본)\n",
    "        - static_prompt (옵션)\n",
    "        - dynamic_prompt (옵션)\n",
    "        - strength, guidance_scale, steps, seed, width, height (SD용)\n",
    "        - use_sd: \"true\" / \"false\"\n",
    "        - num_styles: \"4\"  (몇 장의 AdaIN 스타일을 만들지)\n",
    "    응답(JSON):\n",
    "    {\n",
    "      \"sd\": \"<base64 png or null>\",\n",
    "      \"styles\": [\n",
    "        {\"id\": \"0\", \"image\": \"<base64 png>\"},\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    if \"image\" not in request.files:\n",
    "        return jsonify({\"error\": \"no image file\"}), 400\n",
    "\n",
    "    img = to_rgb_image(request.files[\"image\"])   # 기존에 쓰던 함수 재사용\n",
    "\n",
    "    # --- 옵션 파라미터들 ---\n",
    "    use_sd = request.form.get(\"use_sd\", \"false\").lower() == \"true\"\n",
    "    static_prompt = request.form.get(\"static_prompt\", \"\")\n",
    "    dynamic_prompt = request.form.get(\"dynamic_prompt\", \"\")\n",
    "    prompt = (static_prompt + \", \" + dynamic_prompt).strip(\", \")\n",
    "\n",
    "    strength = float(request.form.get(\"strength\", \"0.5\"))\n",
    "    guidance_scale = float(request.form.get(\"guidance_scale\", \"0.0\"))\n",
    "    steps = int(request.form.get(\"steps\", \"4\"))\n",
    "    seed_str = request.form.get(\"seed\", \"\")\n",
    "    width = int(request.form.get(\"width\", \"512\"))\n",
    "    height = int(request.form.get(\"height\", \"512\"))\n",
    "\n",
    "    num_styles = int(request.form.get(\"num_styles\", \"4\"))\n",
    "    num_styles = max(1, min(num_styles, len(STYLE_IMAGES)))  # 1~len 사이로 클램프\n",
    "\n",
    "    # ---------- 1) Stable Diffusion ----------\n",
    "    img = img.rotate(90)\n",
    "    # img.show()\n",
    "    sd_b64 = None\n",
    "    if use_sd:\n",
    "        try:\n",
    "            generator = None\n",
    "            if seed_str != \"\":\n",
    "                seed = int(seed_str)\n",
    "                generator = np.random.RandomState(seed)\n",
    "\n",
    "            # 기존 /infer에서 쓰던 로직과 최대한 비슷하게\n",
    "            # (입력 회전이 필요하면 img.rotate(90) 등으로 맞춰줘)\n",
    "            out = pipeline(\n",
    "                image=img,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                num_inference_steps=steps,\n",
    "                generator=generator,\n",
    "            )\n",
    "            sd_img: Image.Image = out.images[0]\n",
    "            sd_img = sd_img.rotate(-90)  # 기존 코드에서 하던 회전이 있다면 유지\n",
    "            sd_b64 = pil_to_base64(sd_img)\n",
    "\n",
    "            content_img = sd_img\n",
    "        except Exception as e:\n",
    "            return jsonify({\"error\": f\"SD error: {str(e)}\"}), 500\n",
    "    else:\n",
    "        content_img = img.rotate(-90)\n",
    "    # content_img.show()\n",
    "\n",
    "    # ---------- 2) AdaIN Style Transfer N장 ----------\n",
    "    style_results = []\n",
    "    try:\n",
    "        for idx in range(num_styles):\n",
    "            st_img = run_adain(content_img, STYLE_IMAGES[idx])\n",
    "            style_results.append({\n",
    "                \"id\": str(idx),\n",
    "                \"image\": pil_to_base64(st_img),\n",
    "            })\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"AdaIN error: {str(e)}\"}), 500\n",
    "\n",
    "    return jsonify({\n",
    "        \"sd\": sd_b64,          # 없으면 null\n",
    "        \"styles\": style_results\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d72b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.16.119.217:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [04/Dec/2025 16:47:02] \"POST /infer HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10402723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
